---
title: "Filter sites and operation"
author: "Alain Danet"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
## target knits Rmds in their own session, so load libraries here.
source(here::here("start_rmd.R"))
```

```{r load-targets, include=FALSE}
tar_load(c(op_protocol, site_protocol_quali, site_protocol_quanti))
```

```{r}
op_protocol %>%
  filter(is.na(date), !is.na(month))
op_protocol %>%
  filter(is.na(month), is.na(quarter))
```

```{r}
test_filter <- filter_op(
      op_protocol = op_protocol,
      selected_protocol = NULL,
      nb_sampling = 5,
      extent_month = 1.5,
      return_no_filtered = TRUE,
      convert_month_to_date = TRUE
      )
```

```{r}
ti <- tibble(x = c(1,2))
test_filter %>%
  ggplot(aes(x = (month_duration %% 12))) +
  geom_histogram() +
  geom_vline(data = ti, aes(xintercept = c(12 - 2, 2), color = "2 month")) +
  geom_vline(data = ti, aes(xintercept = c(12 - 1, 1), color = "1 month")) +
  geom_vline(data = ti, aes(xintercept = c(12 - 1.5, 1.5), color = "1.5 month")) +
  scale_color_manual(name = "Number of month",
    values = c(
      "1 month" = "red",
      "1.5 month" = "blue",
      "2 month" = "black"
    )) +
  labs(x = "Number of month ",
    title = "Difference of sampling time between the median time and each
    sampling",
    y = "Frequency")
```

# Summary of analysis 

```{r}
tar_load(filtered_op_protocol)
tar_load(filtered_dataset)
```

```{r}
tabyl_df(filtered_dataset$site_quali, "protocol") %>%
  kable()
```


```{r}
tabyl_df(filtered_dataset$site_quali, "unitabundance") %>%
  kable()
```

- No much site in South America and Africa

```{r}
loc <- filtered_dataset$location %>%
  left_join(filtered_dataset$site_quali, by = "siteid") %>%
  st_as_sf(coords = c("longitude", "latitude"),
  crs = 4326)
```


```{r}
world <- ne_countries(scale = "medium", returnclass = "sf")
ggplot(data = world) +
    geom_sf() +
    geom_sf(data = loc, aes(color = protocol), shape = 1) +
    theme(legend.position = "bottom")
```

```{r}
unique(loc$main_bas) %>% length
unique(loc$waterbody) %>% length

ti <- table(as.factor(loc$main_bas)) %>%
  enframe() %>%
  arrange(desc(value))

ggplot(data = world) +
    geom_sf() +
    geom_sf(data = filter(loc, main_bas %in% ti$name[1:20]),
      aes(color = as.factor(main_bas)), shape = 1) +
    theme(legend.position = "bottom")
```

```{r}
loc %>%
  ggplot(aes(x = protocol, fill = ecoregion)) +
  geom_bar() +
  labs(x = "Protocol", y = "Number of sites") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```


```{r}
loc %>%
  ggplot(aes(x = unitabundance, fill = ecoregion)) +
  geom_bar() +
  labs(x = "Abundance unit", y = "Number of sites") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```



```{r}
site_year <- filtered_dataset$site_quanti %>%
  filter(variable == "year") %>%
  left_join(filtered_dataset$location, by = "siteid") %>%
  mutate(
    span = max - min + 1,
    completeness = n / (span),
    cat_span = cut(span, c(0, 10, 20, 30, 40, 70), right = TRUE,
      include.lowest = TRUE
    ),
    cat_completeness = cut(
      completeness, c(0, .1, .25, .5, .75, 1), right = TRUE,
      include.lowest = TRUE
    )
    )
```

```{r, results="hide"}
map_dfr(c("span", "completeness", "min", "median", "max", "n"),
  ~tibble(
    variable = .x, 
    median = median(site_year[[.x]]))
)
```


```{r}
site_year %>%
  ggplot(aes(x = min)) +
  geom_histogram() +
  labs(x = "Baseline year", y = "Number of sites") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```


```{r}
site_year %>%
  ggplot(aes(x = cat_span, fill = ecoregion)) +
  geom_bar() +
  labs(x = "Year span (year)", y = "Number of sites") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
site_year %>%
  ggplot(aes(x = cat_completeness, fill = ecoregion)) +
  geom_bar() +
  labs(
    x = "Completeness of sampling (nb sampling / year span )",
    y = "Number of sites"
  )
```

```{r}
site_year %>%
  ggplot(aes(x = n, fill = ecoregion)) +
  geom_bar() +
  labs(
    x = "nb sampling",
    y = "Number of sites"
  )
```

# Diversity

```{r}
tar_load(c(chao_hillnb, hillebrand, filtered_dataset))
```

```{r}
var_chao <- c("chao_richness", "chao_shannon", "chao_simpson")
chao_summary <- map_dfr(chao_hillnb[, var_chao],
  ~summary_distribution(.x, na.rm = TRUE), .id = "variable"
  )

chao_summary %>%
  kable()
```

```{r}
chao_hillnb[, var_chao] %>%
  pivot_longer(., cols = c(var_chao)) %>%
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_grid(cols = vars(name), scales = "free_x")
```

- Chao methods on abundance density seems to fail
  - Update: fixed

```{r}
stopifnot(all(chao_summary$n_na == 0))
```

- However, chao shannon is NA when all abundances are equal
  - When all abundances are equal and since hill numbers are computed with the
    natural logarythm, shannon should be equal to ln($D^0$), $D^O$ being the
    species richness
  - Let's replace equal abundances NA's shannon by ln(chao richness) 

```{r, eval=FALSE}
chao_hillnb %>%
  filter(is.na(chao_shannon))

mask_na <- chao_hillnb[is.na(chao_hillnb$chao_shannon), ]$op_id
ti <- filtered_dataset$measurement %>%
  filter(op_id == na.omit(mask_na)[4])
ti <- filtered_dataset$measurement %>%
  group_by(op_id) %>%
  mutate(abundance = round(adjust_abun_chao(abundance))) %>%
  ungroup() %>%
  nest_by(op_id)
tid <- map(ti$data, "abundance")
names(tid) <- ti$op_id 
mesure <- furrr::future_map_dfr(
  tid, ~c(n_unique = length(unique(.x))),
    .id = "op_id"
    )
mesure[is.na(chao_hillnb$chao_shannon), ]$n_unique == 1


vegan::diversity(round(adjust_abun_chao(ti$abundance)))
invChat.Ind_c(round(adjust_abun_chao(ti$abundance)), C = .985, conf = NULL)

shannon_na_unique_abun <- filtered_dataset$measurement %>%
  filter(op_id %in% na.omit(mask_na)) %>%
  group_by(op_id) %>%
  mutate(abun_adjusted = round(adjust_abun_chao(abundance))) %>%
  summarise(
    n_unique = length(unique(abundance)),
    n_ajust = length(unique(abun_adjusted))
  )
```

- Same thing with Chao, simpson should be 0 when one species only.

```{r, eval=FALSE}
chao_hillnb %>%
  filter(is.na(chao_simpson))


mask_na <- chao_hillnb[is.na(chao_hillnb$chao_simpson), ]$op_id
ti <- filtered_dataset$measurement %>%
  filter(op_id == na.omit(mask_na)[4])


vegan::diversity(round(adjust_abun_chao(ti$abundance)), index = "simpson")
invChat.Ind_c(round(adjust_abun_chao(ti$abundance)), C = .985, conf = NULL)

filtered_dataset$measurement %>%
  filter(op_id %in% na.omit(mask_na))

simpson_na_unique_abun <- filtered_dataset$measurement %>%
  filter(op_id %in% na.omit(mask_na)) %>%
  group_by(op_id) %>%
  mutate(abun_adjusted = round(adjust_abun_chao(abundance))) %>%
  summarise(
    n = n(),
    n_unique = length(unique(abundance)),
    n_ajust = length(unique(abun_adjusted))
  )
```



```{r, eval=FALSE}
chao_hillnb %>%
  filter(chao_shannon == c("-Inf", "Inf"))
chao_hillnb[42923, ]

mask_minus_inf <- chao_hillnb[chao_hillnb$chao_shannon == "-Inf", ]$op_id
ti <- filtered_dataset$measurement %>%
  filter(op_id == na.omit(mask_minus_inf)[1])

rec <- adjust_abun_chao(ti$abundance)
invChat.Ind_c(ti$abundance, C = .985, conf = NULL)
invChat.Ind_c(as.integer(round(ti$abundance)), C = .985, conf = NULL)
invChat.Ind_c(rec, C = .985, conf = NULL)
invChat.Ind_c(as.integer(round(rec)), C = .985, conf = NULL)
Dqhat.Ind


mask_inf <- chao_hillnb[chao_hillnb$chao_shannon == "Inf", ]$op_id

ti <- filtered_dataset$measurement %>%
  filter(op_id %in% na.omit(mask_inf)[2])

invChat.Ind_c(ti$abundance %>% round, C = .985, conf = NULL)
invChat.Ind_c(ti$abundance, C = .985, conf = NULL)
vegan::diversity(ti$abundance)
```

```{r, eval=FALSE}
chao_hillnb %>%
  filter(chao_shannon == "Inf")
any(chao_hillnb$chao_shannon == "Inf" & chao_hillnb$method == "interpolated")
any(chao_hillnb$chao_shannon == "Inf" & chao_hillnb$method != "interpolated")

ti <- filtered_dataset$measurement %>%
  filter(op_id == "nfp136")

chao_hillnb[4230, ]
invChat.Ind_c((ti$abundance), C = .985, conf = NULL)
invChat.Ind_c((ti$abundance) * 100, C = .985, conf = NULL)
```

- On va multiplier les densité d'abondances par le minimum pour que l'abondance minimal soit de 1 pour les calculs de chao
  - ça va pas affecter négativement le chao car il n'est pas basé sur l'effort
    d'échantillonnage
  - ça fait sens
  - ça augmente le nombre de singleton mais au augmentant au minimum le nombre
    d'individus total dans la communauté

# Spatial assessment


```{r, eval=TRUE}
tar_load(spde)
plot(spde)
```



# Environment

## River atlas 

```{r}
tar_load(riveratlas_site)
```

```{r}
# Elevation
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "ele_")]
# Slope
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "slp_")]
# Temperature
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "tmp_")]
# River position
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "tmp_")]
# River discharge 
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "dis_m3")]
colnames(riveratlas_site)[str_detect(colnames(riveratlas_site), "ria_")]
```

```{r}
riveratlas_site <- riveratlas_site %>%
  mutate(across(starts_with("tmp_"), ~.x / 10))
```


```{r}
riv <- riveratlas_site %>%
  select(all_of(get_river_atlas_significant_var())) %>%
  st_drop_geometry()

```

```{r}
riv %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "values") %>%
  ggplot(aes(x = values)) +
  geom_histogram() +
  facet_wrap(~variable, scales = "free_x")
```

```{r}
library(ade4)
library(factoextra)

pca_riv <- dudi.pca(df = scale(riv), scannf = FALSE, nf = 3)
```

- We see two main axis (as I found in France):
  - First axis related to stream size (distance from source, River area)
  - Second axis related to Temperature 

```{r}
fviz_eig(pca_riv)

p_pca <- map(list(c(1,2), c(2, 3), c(1, 3)),
  ~fviz_pca_var(pca_riv,
    axes = .x,
    col.var = "contrib", # Color by contributions to the PC
    gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
    repel = TRUE     # Avoid text overlapping
    ) +
  theme(legend.position = "none") + labs(title = "")
)

plot_grid(plotlist = p_pca, ncol = 1)
p_pca[[1]]
p_pca[[2]]
p_pca[[3]]
```
## Water temperature 

```{r}
tar_load(c(wt_mv_avg, filtered_dataset))
wt_mv_avg  <- wt_mv_avg %>%
  ungroup()
```
```{r}
library(glmmTMB)
library(DHARMa)
library(ggeffects)
library(emmeans)
mod_wt_data <- wt_mv_avg  %>%
  left_join(
    filtered_dataset$location %>%
    select(siteid, ecoregion, main_bas) %>%
    mutate(main_bas = as.character(main_bas)),
    by = "siteid"
  )

tabyl_df(mod_data, "ecoregion")
length(unique(mod_data$siteid))
```

```{r}
hist(mod_data$tmp_w_ama)
```


```{r}
#https://stackoverflow.com/questions/66467641/partial-effect-plots-from-spamm

# Put ecoregion as a fixed effect because not enough ecogion data to estimate the
# random effect:
#mod_wt <- glmmTMB(
#  tmp_w_ama ~ year * ecoregion +
#    (1 + year | main_bas/siteid),
#  data = mod_data)
load(here::here("data", "mod_wt.rda"))
tar_load(mod_wt)

#vignette('troubleshooting')
diagnose(mod_wt)
confint(mod_wt)
emmeans::emmeans(mod_wt, "year", type = "response")
sim_res <- DHARMa::simulateResiduals(mod_wt)
plot(sim_res)
```
```{r}
pr <- ggpredict(mod_wt, "year")
plot(pr)

# No
me <- ggpredict(mod_wt,
  terms = c("year", "ecoregion"),
  type = "random")
plot(me)

#
bas <- ggpredict(mod_wt,
  terms = c("year", "main_bas [sample=8]"),
  type = "random")
plot(bas)
```


```{r}
coef_wt <- coef(mod_wt)
coef_site <- coef_wt$cond$`siteid:main_bas` %>%
  mutate(
    siteid = stringr::str_split(row.names(coef_wt$cond$`siteid:main_bas`), ":") %>%
  map_chr(., 1),
main_bas = stringr::str_split(row.names(coef_wt$cond$`siteid:main_bas`), ":") %>%
  map_chr(., 2)
  )

loc_wt_year_slp <- filtered_dataset$location %>%
  st_as_sf(coords = c("longitude", "latitude"),
  crs = 4326) %>%
left_join(coef_site, by = "siteid")
```

```{r}
ggplot(data = world) +
    geom_sf() +
    geom_sf(data = loc_wt_year_slp, aes(fill = year * 10), shape = 21) +
    scale_fill_viridis() +
    theme(legend.position = "bottom")
```

```{r}
coef_bas <- coef_wt$cond$`main_bas` %>%
  mutate( main_bas = row.names(coef_wt$cond$`main_bas`))
```

```{r}
loc_wt_year_slp_bas <- filtered_dataset$location %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  mutate(main_bas = as.character(main_bas)) %>%
  left_join(coef_bas, by = "main_bas")
```

```{r}
ggplot(data = world) +
    geom_sf() +
    geom_sf(data = loc_wt_year_slp_bas, aes(fill = year * 10), shape = 21) +
    scale_fill_viridis() +
    theme(legend.position = "bottom")
```







## Analysis

## Reproducibility

<details><summary>Reproducibility receipt</summary>

```{r}
## datetime
Sys.time()

## repository
if(requireNamespace('git2r', quietly = TRUE)) {
  git2r::repository()
} else {
  c(
    system2("git", args = c("log", "--name-status", "-1"), stdout = TRUE),
    system2("git", args = c("remote", "-v"), stdout = TRUE)
  )
}

## session info
sessionInfo()
```

</details>
