---
title: "Modelling temporal trends"
author: "Alain Danet"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
source(here::here("start_rmd.R"))
```

```{r}
library(INLA)
library(inlatools)
library(inlabru)
library(spaMM)
library("glmmTMB")
library(DHARMa)
library(ggeffects)
library(emmeans)
```


```{r load-targets, include=FALSE}
tar_load(c(filtered_dataset, analysis_dataset, var_temporal_trends))
```

# Model ALL in ONE  

## spaMM

### Jaccard

- Quite a lot of 0 and 1, it can be problematic for beta regression 

```{r}
hist(analysis_dataset$jaccard)
summary(analysis_dataset$jaccard)
```

```{r}
x <- rbinom(20, 1, .5)
transform01(x)
analysis_dataset$jaccard_scaled <- transform01(analysis_dataset$jaccard)
analysis_dataset$main_bas <- as.character(analysis_dataset$main_bas)
```
- Better to transform variable on the na.omit data 

```{r}
summary(analysis_dataset$jaccard_scaled)
ti <- analysis_dataset %>%
  na.omit() %>%
  mutate(jaccard_scaled = transform01(jaccard))
summary(ti[, c("jaccard", "jaccard_scaled")])
```



```{r}
analysis_dataset %>%
  filter(siteid %in% sample(unique(siteid))[1:60]) %>%
  ggplot(aes(y = jaccard_scaled, x = year, color = siteid)) +
  geom_line() +
  theme(legend.position = "none")
```


```{r, eval=FALSE}
# https://stats.stackexchange.com/q/423274
ti <- glmmTMB(jaccard_scaled ~ year * ecoregion +
  (1 + year | main_bas/siteid),
  family = list(family = "beta", link = "logit"),
  data = na.omit(analysis_dataset[, c("siteid", "jaccard_scaled", "year",
      "species_nb", "ecoregion", "main_bas")]))
```
```{r, eval=FALSE}
plot(resid(ti) ~ fitted(ti))
```
```{r, eval=FALSE}
ti1 <- update(ti, dispformula = ~ species_nb)
```

```{r, eval=FALSE}
plot(resid(ti1) ~ fitted(ti1))
```

### Test

```{r}
tar_load(fr)
skimr::skim(fr)
```
```{r}
hist(fr$jaccard_scaled)
tabyl_df(fr, "main_bas")
```

- Relationships between jaccard and year number are highly non linear: 
  - it might be more appropriate to model them with `log(year_nb)` to model
    linearly a negative exponential relationship. However it should not catch
    recovery from disturbance

```{r}
fr %>%
  filter(siteid %in% sample(unique(siteid))[1:10]) %>%
  ggplot(aes(y = jaccard_dis, x = year_nb, color = siteid)) +
  geom_line() +
  theme(legend.position = "none") +
  geom_smooth(se = FALSE)
```

- It is not pretty but seems not too bad:

```{r, fig.cap="Example with 10 sites"}
sample_fr <- fr %>%
  filter(siteid %in% sample(unique(siteid))[1:10])
sample_fr %>%
  ggplot(aes(y = jaccard_scaled, x = log(year_nb + 1), color = siteid)) +
  geom_point() +
  theme(legend.position = "none") +
  geom_smooth(linetype = 2, se = FALSE) +
  geom_smooth(
    linetype = 1,
    formula = y ~ x,
    method = "lm",
    se = FALSE
    )
```

- There are a clear relationship between stralher order and jaccard:
  - Higher turnover through time in higher stralher order, it is expected because there are
    more connected, larger, far from the source, and so a higher dispersion rate. 


```{r}
fr %>%
  ggplot(aes(y = jaccard_scaled, x = year_nb, color = as.factor(ord_stra))) +
  geom_point() +
  geom_smooth(se = FALSE)
```

- Logging year number improved the linear shape of the relationship but that is
  far from being perfect

```{r}
fr %>%
  ggplot(
    aes(y = jaccard_scaled, x = log(year_nb + 1), color = as.factor(ord_stra))
  ) +
  geom_point() +
  geom_smooth(se = FALSE) +
  geom_smooth(method = "lm", se = FALSE)
```

- Logging both response and predictor do not improve stuff:

```{r}
fr %>%
  ggplot(
    aes(y = log(jaccard_scaled + 1), x = log(year_nb + 1), color = as.factor(ord_stra))
    ) +
  geom_point() +
  geom_smooth(se = FALSE)
```

- Temperature:

```{r}
fr %>%
  mutate(tmp_cat = cut(scaled_tmp_c_cyr, breaks = 8)) %>%
  ggplot(aes(y = jaccard_scaled, x = year_nb, color = as.factor(tmp_cat))) +
  geom_point() +
  geom_smooth(se = FALSE)
```

- Are there two synergistic effects here, like dissimilarity increase more far
  the source (dispersal effect) but at the same dissimilarity increase more in
  warm water, both variables might be collinear, right?

```{r}
fr %>%
  ggplot(aes(y = tmp_c_cyr, x = as.factor(ord_stra))) +
  geom_violin()
```

- Collinearity is weak between temperature and strahler, so it is good:


```{r}
cor(fr$tmp_c_cyr, fr$ord_stra, method = "spearman")
car::vif(lm(jaccard_scaled ~ scaled_tmp_c_cyr + scaled_dist_up_km, fr))
```

- Compare different model : 


```{r, fig.cap="Example with 10 sites. Test with GAM, quadradic and linear models"}
sample_fr <- fr %>%
  filter(siteid %in% sample(unique(siteid))[1:10])
sample_fr %>%
  ggplot(
    aes(y = jaccard_scaled,
      x = log(year_nb + 1),
      color = siteid)
    ) +
  geom_point() +
  theme(legend.position = "bottom") +
  geom_smooth(linetype = 2, se = FALSE) +
  geom_smooth(
    linetype = 1,
    formula = y ~ x,
    method = "lm",
    se = FALSE
    ) +
  geom_smooth(
    linetype = 3,
    formula = y ~ x + poly(x, 2),
    method = "lm",
    se = FALSE
    )
```

```{r}
knitr::opts_chunk$set(eval = FALSE)
```

# Diagnose models 

```{r}
tar_load(c(gaussian_jaccard_tmb, modelling_data))
obj_mb(gaussian_jaccard_tmb)
```

- See gaussian model with relaxed intercept:

```{r}
g_jac_1_ly <- filter(gaussian_jaccard_tmb) %>%
  filter(intercept == 1, year_var == "log1_year_nb")
```

- Diagnostic reveals that the models fail for basin "3" 

```{r}
ti <- diagnose(g_jac_1_ly$mod[[7]])
ss <- summary(g_jac_1_ly$mod[[7]]$sdr) 
ss[grepl("^(beta|theta)", rownames(ss)), ]

broom.mixed::tidy(g_jac_1_ly$mod[[7]])
```

```{r}
modelling_data %>%
  filter(main_bas == levels(modelling_data$main_bas)[3])

confint(, "log1_year_nb", component = "cond")

```

```{r}
ti <- get_random_effect_glmmTMB(g_jac_1_ly$mod[[7]], effect = "main_bas")
hist(ti[["log1_year_nb"]])
```




```{r, eval = FALSE}
filter()
confint(beta_jaccard_tmb)
analysis_dataset
res_b_j <- simulateResiduals(beta_jaccard_tmb)

summary(beta_jaccard_tmb)
library(emmeans)
x <- coef(beta_jaccard_tmb)$cond
str(x)
y <- x[["siteid:main_bas"]]
emmeans(beta_jaccard_tmb, "year_nb", type = "response")
r2(beta_jaccard_tmb)
```

```{r, eval = FALSE}
pred <- ggemmeans(beta_jaccard_tmb,
  terms = c("year_nb", "scaled_dist_up_km [quart2]"),
  type = "re.zi")
plot(pred)
```

```{r, eval = FALSE}
tar_load(c(rigal_trends, var_temporal_trends))
names(rigal_trends) <- var_temporal_trends

hist(coef(beta_jaccard_tmb)$cond[["siteid:main_bas"]]$year_nb)
```


- Site:

```{r, eval=FALSE}
tar_load(gaussian_jaccard_tmb)
par(mfrow = c(1, 2))
hist(coef(gaussian_jaccard_tmb)$cond[["siteid:main_bas"]]$year_nb)
hist(rigal_trends[["jaccard"]]$linear_slope)
```
```{r}
plot(
  coef(gaussian_jaccard_tmb)$cond[["siteid:main_bas"]]$year_nb,
  coef(beta_jaccard_tmb)$cond[["siteid:main_bas"]]$year_nb,
  xlim= c(-.5,.2), ylim = c(-.5,.2)
)
abline(0,1)
```

- Basin:

```{r}
ti <- get_random_effect_glmmTMB(g_jac_1_ly$mod[[7]], effect = "main_bas")
hist(ti$log1_year_nb)
```


```{r}
tar_load(filtered_dataset)
loc <- filtered_dataset$location %>%
  left_join(filtered_dataset$site_quali, by = "siteid") %>%
  st_as_sf(coords = c("longitude", "latitude"),
  crs = 4326)
```

```{r}
loc_slp <- loc %>%
  left_join(select(x, -main_bas), by = c("siteid"))

world <- ne_countries(scale = "medium", returnclass = "sf")
bb <- st_bbox(loc)
ggplot(data = world) +
    geom_sf() +
    geom_sf(data = loc_slp, aes(color = year_nb), shape = 23) +
    scale_color_viridis() +
    theme(legend.position = "bottom") +
    labs(title = paste0("Number of sites: ", nrow(loc)))
length(unique(na.omit(analysis_dataset)$siteid))
```



```{r}
ti <- glmmTMB(
  jaccard_scaled ~ 0 + year_nb * scaled_dist_up_km +
  (0 + year_nb | main_bas/siteid),
offset = rep(1.0, nrow(fr)),
  family = beta_family(link = "logit"),
  data = fr)
diagnose(ti)
```

```{r}
res_sim <- simulateResiduals(ti)
plot(res_sim)
plot(residuals(ti) ~ fitted(ti))
plot(fr$jaccard_scaled ~ fitted(ti))
```

```{r}
confint(ti)
```

```{r}
ti1 <- update(ti, dispformula = ~ year_nb)
diagnose(ti1)
```

```{r}
res_sim1 <- simulateResiduals(ti1)
plot(res_sim1)

confint(ti1)
```

```{r}
ti2 <- update(ti1, dispformula = ~ year_nb + scaled_dist_up_km)
diagnose(ti2)
```

```{r}
res_sim2 <- simulateResiduals(ti2)
plot(res_sim2)

confint(ti2)
```

```{r}
ti3 <- update(ti2, formula = jaccard_scaled ~
  0 + year_nb/scaled_dist_up_km +
  (0 + year_nb | main_bas/siteid))
diagnose(ti3)
```

```{r}
res_sim3 <- simulateResiduals(ti3)
plot(res_sim3)

confint(ti3)
```


- Normal distribution:

```{r}
?family_glmmTMB
tn <- glmmTMB(jaccard_scaled ~
  0 + year_nb * scaled_dist_up_km +
  (0 + year_nb | main_bas/siteid) +
  (0 + scaled_dist_up_km | main_bas),
offset = rep(1.0, nrow(fr)),
  family = gaussian(link = "identity"),
  data = fr)
diagnose(tn)
summary(tn)
plot(resid(tn) ~ fitted(tn))
plot(fr$jaccard_scaled ~ fitted(tn))
abline(c(0,1))
```

```{r}
confint(tn)
```

### Species richness

```{r}
sp_tmb <- glmmTMB(species_nb ~
  year_nb * scaled_dist_up_km +
  (1 + year_nb | main_bas / siteid) +
  (1 + scaled_dist_up_km | main_bas),
  offset = NULL,
  dispformula = ~1,
  family = nbinom2(link = "log"),
  data = fr)
diagnose(sp_tmb)
```
```{r}
res_sp <- simulateResiduals(sp_tmb)
plot(res_sp)
testDispersion(res_sp)
testZeroInflation(res_sp)
```
```{r}
sp_tmb1 <- update(sp_tmb,
  formula = species_nb ~
  year_nb +
  (1 + year_nb | main_bas / siteid) +
  (1 + scaled_dist_up_km | main_bas),
  ziformula = ~ main_bas + siteid)
diagnose(sp_tmb1)
```
```{r}
res_sp1 <- simulateResiduals(sp_tmb1)
plot(res_sp1)
testDisp1ersion(res_sp1)
testZeroInflation(res_sp1)
```

### Total abundance 

```{r, eval=FALSE}
tar_load(c(site_protocol_quali, site_protocol_quanti))
tar_load(op_protocol)
analysis_dataset
tabyl_df(analysis_dataset, "unitabundance")
tabyl_df(site_protocol_quali, "unitabundance")
tabyl_df(
  mutate(op_protocol, sample_effort = is.na(sampledlength_m)),
  "sample_effort"
)
filtered_dataset
analysis_dataset %>%
  left_join(select(op_protocol, op_id, sampledlength_m), by = "op_id") %>%
  filter(is.na(sampledlength_m)) %$%
  tabyl_df(., "unitabundance")

sum(is.na(analysis_dataset$unitabundance))

hist(analysis_dataset$total_abundance)
```


```{r}
abun <- glmmTMB(
  total_abundance ~ year_nb * unitabundance + (1 + year_nb | main_bas / siteid),
  data = analysis_dataset
)

plot(get_data(abun)$total_abundance ~ predict(abun))
abline(0, 1)

plot(log10(get_data(abun)$total_abundance + 1) ~ log10(predict(abun) +1))
abline(0, 1)

diagnose(abun)
abun_res <- DHARMa::simulateResiduals(abun)
plot(abun_res)
```

```{r}
site_abun <- get_random_effect_glmmTMB(abun, effect = "siteid:main_bas")
site_abun %>%
  left_join(analysis_dataset %>%
    select(siteid, unitabundance) %>%
    group_by(siteid) %>%
    summarise(unitabundance = unique(unitabundance), .group = "drop"), by = "siteid") %>%
  ggplot(aes(x = year_nb)) +
  geom_histogram() +
  facet_wrap(~unitabundance, scale = "free")
```


- With siteid:

```{r}
log_abun <- glmmTMB(
  log_total_abundance ~ year_nb + unitabundance + (1 + year_nb | main_bas/siteid),
  data = analysis_dataset)

get_random_effect_glmmTMB(abun, effect = "siteid:main_bas")

diagnose(abun)
abun_res <- DHARMa::simulateResiduals(abun)
plot(abun_res)

plot(get_data(log_abun)$log_total_abundance ~ predict(log_abun))
abline(0, 1)
```


- With siteid:

```{r}
abun_siteid <- update(abun,
  formula = total_abundance ~
    log1_year_nb +
    (1 + log1_year_nb | unitabundance/siteid)
)

diagnose(abun_siteid)

get_random_effect_glmmTMB(abun_siteid, effect = "unitabundance")
get_random_effect_glmmTMB(abun_siteid, effect = "siteid:unitabundance")

abun_siteid_res <- DHARMa::simulateResiduals(abun_siteid)
plot(abun_siteid_res)
testDispersion(abun_siteid_res)

testCategorical(abun_siteid_res, catPred = analysis_dataset$unitabundance)
```

```{r}
scaled_abun <- analysis_dataset %>%
  group_by(unitabundance) %>%
  mutate( total_abundance_scaled = as.numeric(scale(total_abundance))) %>%
  ungroup()
hist(scaled_abun$total_abundance_scaled)

abun_scaled_siteid <- update(abun_siteid,
  formula = total_abundance_scaled ~
    year_nb +
    (1 + year_nb | unitabundance/siteid),
  data = scaled_abun
)
diagnose(abun_scaled_siteid)

abun_scaled_siteid <- DHARMa::simulateResiduals(abun_scaled_siteid)
plot(abun_scaled_siteid)

```

```{r}
# Why not test with a gamma with dispersion parameter?
#https://stats.stackexchange.com/questions/481109/glmm-hurdle-model-for-continuous-data-truncated-negative-binomial-family-in-glm

sample_unit <- scaled_abun %>%
  filter(!unitabundance %in% c("Leslie_index", "CPUE")) %>%
  group_by(unitabundance) %>%
  filter(siteid %in% sample(unique(siteid), 30)) %>%
  ungroup
tabyl_df(sample_unit, "unitabundance")

abun_unitabun_siteid <- glmmTMB(
  formula = total_abundance ~
    year_nb +
    (1 + year_nb | siteid),
  data = sample_unit,
  family = Gamma(),
  dispformula = ~ unitabundance
)
diagnose(abun_unitabun_siteid)

abun_unitabun_siteid_res <- DHARMa::simulateResiduals(abun_unitabun_siteid)
plot(abun_unitabun_siteid_res)
```


```{r}
abun_unitabun <- glmmTMB(
  total_abundance ~ year_nb + (1 + year_nb | unitabundance),
  data = sample_unit)
diagnose(abun_unitabun)
abun_unitabun_res <- DHARMa::simulateResiduals(abun_unitabun)
plot(abun_unitabun_res)

get_random_effect_glmmTMB(log_abun, effect = "unitabundance")
```

```{r}
abun_unitabun <- glmmTMB(
  total_abundance ~ year_nb + (1 + year_nb | unitabundance),
  data = sample_unit)
abun_unitabun_res <- DHARMa::simulateResiduals(abun_unitabun)
plot(abun_unitabun_res)

get_random_effect_glmmTMB(log_abun, effect = "unitabundance")
```

```{r}
abun_unitabun_siteid <- glmmTMB(
  total_abundance ~ year_nb + unitabundance
    (1 + year_nb | siteid),
  data = sample_unit)
diagnose(abun_unitabun_siteid)
abun_unitabun_res <- DHARMa::simulateResiduals(abun_unitabun)
plot(abun_unitabun_res)

get_random_effect_glmmTMB(log_abun, effect = "unitabundance")
```

- No modelling strategy works well, may be model as Lise suggested, abundance as
  change from first year:

```{r}
abun_tps <- analysis_dataset %>%
    arrange(siteid, year) %>%
    nest_by(siteid) %>%
    mutate(
      abun_tps = list(
        tibble(
          year = data$year,
          abun_tps = compute_metric_temporal_diff(
            year = data$year,
            y = data$total_abundance
          )
        )
      )
      ) %>%
    ungroup() %>%
    select(-data) %>%
    unnest(abun_tps)

hist(abun_tps$abun_tps)
hist(log10(abun_tps$abun_tps + 2))
```

```{r}
hist(analysis_dataset$total_abundance)
hist(log10(analysis_dataset$total_abundance))
```

```{r}
site_abun100 <- abun_tps %>%
  filter(abun_tps >= 100) %$%
  unique(.$siteid)
analysis_dataset %>%
  filter(siteid %in% sample(site_abun100, 10)) %>%
  ggplot(
    aes(x = year_nb, y = total_abundance, color = siteid)) +
  geom_line()
```



```{r}
analysis_dataset_tps <-
  analysis_dataset %>%
  left_join(abun_tps, by = c("siteid", "year")) %>%
  filter(!is.na(main_bas), !is.na(siteid))
```

```{r}
analysis_dataset_tps %>%
  filter(year_nb == 0) %>%
  select(abun_tps)
```

```{r}
abun_tps_siteid <- glmmTMB(
  abun_tps ~ 0 + log1_year_nb + (0 + log1_year_nb | main_bas/siteid),
  data = filter(analysis_dataset_tps, siteid != "S1000", main_bas != "1080024070"))

diagnose(abun_tps_siteid)
abun_tps_siteid_res <- DHARMa::simulateResiduals(abun_tps_siteid)
plot(abun_tps_siteid_res)

get_random_effect_glmmTMB(abun_tps_siteid, effect = "main_bas")

x <- get_random_effect_glmmTMB(abun_tps_siteid, effect = "siteid:main_bas") %>%
  arrange(desc(abs(log1_year_nb)))
hist(x[[3]])
```

```{r}
analysis_dataset_tps %>%
  filter(siteid %in% sample(siteid, 10)) %>%
  ggplot(
    aes(x = log1_year_nb, y = abun_tps, color = siteid)) +
  geom_line() +
  geom_smooth(method = "lm", se = FALSE)
```

```{r}
analysis_dataset_tps %>%
  filter(siteid %in% sample(siteid, 10)) %>%
  ggplot(
    aes(x = year_nb, y = abun_tps, color = siteid)) +
  geom_line() +
  geom_smooth(method = "lm", formula = y ~ x + lag(x), se = FALSE)
```


```{r}
abun_tps_siteid <- glmmTMB(
  abun_tps ~ 1 + year_nb + lag(year_nb) + (1 + year_nb | main_bas/siteid),
  data = analysis_dataset_tps[,c("siteid",)]
  )
diagnose(abun_tps_siteid)

abun_tps_siteid_res <- DHARMa::simulateResiduals(abun_tps_siteid)
plot(abun_tps_siteid_res)

get_random_effect_glmmTMB(abun_tps_siteid, effect = "main_bas")
```

```{r}
ti <- get_data(abun_tps_siteid)
abun_tps_siteid@data
na.omit(analysis_dataset_tps)
y <- log(predict(abun_tps_siteid) + 1)
plot(
  log(ti$abun_tps +1) ~ y,
  xlim = c(0, 5)
)
abline(0,1)
```






## INLA 

- General model of Van Klink: 

```{r, eval=FALSE}
inla(x ~ Year: Realm: U + Realm + U +
  f(Period, model = 'iid')+
  # random intercept season
  f(Plot_ID, model = 'iid')+
  # random intercept site
  f(StudyArea_ID, model='iid')+
  # random intercept study area
  f(Datasource_ID, model='iid')+
  # random intercept study
  f(Plot_ID_slope, iYear, model='iid')+
  # random slope site
  f(StudyArea_ID_slope, iYear, model='iid')+
  # random slope study area
  f(Datasource_ID_slope, Year, model='iid') +
  # random slope study
  f(Year,model='ar1', replicate=as.numeric(Plot_ID)), # AR1 term
family="gaussian"
# normal distribution
)
```


# Test

## Test Illinois

```{r}
site_il <- filtered_dataset$location %>%
  filter(region == "ILLINOIS")
fish_il <- filtered_dataset$measurement %>%
  filter(siteid %in% site_il$siteid)
il_dataset <- fish_il %>%
  left_join(site_il, by = "siteid")
```

```{r}
m0 <- inla(abundance ~ 1, data = il_dataset)
m0_1 <- inla(abundance ~ 1, family = "poisson", data = il_dataset)
m1 <- inla(abundance ~ year, family = "poisson", data = il_dataset)
m1_1 <- inla(abundance ~ as.factor(year), family = "poisson", data = il_dataset)

```

```{r}
p <- map(unique(unique(il_dataset$siteid)),
  ~plot_temporal_population(com = filter(il_dataset, siteid == .x))
)
plot_grid(plotlist = p[1:4])
plot_grid(plotlist = p[5:8])
plot_grid(plotlist = p[9:12])
```

```{r}
il_abun_rich <- filtered_dataset$abun_rich_op %>%
  filter(siteid %in% site_il$siteid)
```
```{r}
a1 <- inla(total_abundance ~ year,
  family = "poisson",
  control.family=list(link='log'),
  data = il_abun_rich)
```

```{r}
get_data_pred_inla <- function(dataset = NULL, predictor = NULL, y = NULL) {

  fitted <- dataset[, c(y, predictor)]
  fitted[[y]] <- NA
  l <- map(predictor, ~seq(min(dataset[[.x]]), max(dataset[[.x]]), len = 100))
  names(l) <- predictor
  l[[y]] <- NA
  newdata <- expand.grid(l)
  dat_pred <- bind_rows(dataset, fitted, newdata)
  list(
    dat_pred = dat_pred,
    newdata = newdata,
    fitted = fitted,
    rows = (nrow(dataset) + nrow(fitted)+1):nrow(dat_pred)
  )
}
test <- get_data_pred_inla(dataset = il_abun_rich, predictor = "year", y =
  "total_abundance")
```
```{r}
a1 <- inla(total_abundance ~ year,
  family = "poisson",
  control.family = list(link='log'),
  control.predictor = list(link=1, compute=TRUE),
  data = test$dat_pred)
summary(a1)
```
```{r}
newdata <- cbind(
  test$newdata,
  a1$summary.fitted.values[test$rows,])
newdata <- rename(newdata, "lower" = "0.025quant", "upper"="0.975quant")

ggplot(newdata, aes(y = mean, x = year)) +
        geom_blank() +
        geom_point(data = il_abun_rich, aes(y = total_abundance, x = year)) +
        geom_ribbon(aes(ymin = lower-100, ymax = upper+100), fill = 'blue', alpha = 0.2) +
        geom_line()
```


```{r}
a2 <- inla(total_abundance ~ year,
  family = "nbinomial",
  control.family = list(link='log'),
  control.predictor = list(link=1, compute=TRUE),
  data = test$dat_pred)
```
```{r}
newdata <- cbind(
  test$newdata,
  a2$summary.fitted.values[test$rows,])
newdata <- rename(newdata, "lower" = "0.025quant", "upper"="0.975quant")

ggplot(newdata, aes(y = mean, x = year)) +
        geom_blank() +
        geom_point(data = il_abun_rich, aes(y = total_abundance, x = year)) +
        geom_ribbon(aes(ymin = lower, ymax = upper), fill = 'blue', alpha = 0.2) +
        geom_line()
```

```{r}
a3 <- inla(total_abundance ~ year + f(siteid, model = "iid"),
  family = "nbinomial",
  control.family = list(link = "log"),
  control.predictor = list(link = 1, compute = TRUE),
  control.compute = list(cpo = TRUE, dic = TRUE, config = TRUE),
  data = test$dat_pred)
plot(a3)
```
- inlatools checks:

```{r}
check <- distribution_check(a3, nsim = 100)
plot(check)
disp <- dispersion_check(a3)
plot(disp)
```


```{r}
post <- inla.posterior.sample(n = 100, result = a3)

relevant <- grep("^Predictor:", rownames(post[[1]]$latent))
eta <- map_dfc(post, "latent")[relevant, , drop = FALSE]

relevant <- grep(
  "size for the nbinomial observations",
  names(post[[1]]$hyperpar)
)
size <- inla.hyperpar.sample(n = 100, result = a3)[, relevant] #nolint
simulated_values <- as_tibble(mutate_all(
  exp(eta),
  function(mu) {
    rnbinom(n = length(mu), mu = mu, size = size)
  }
  ))

library(DHARMa)
relevant_data <- !is.na(test$dat_pred$total_abundance)
sim <- createDHARMa(
  simulatedResponse = as.matrix(simulated_values)[relevant_data,],
  observedResponse = test$dat_pred$total_abundance[relevant_data],
  fittedPredictedResponse = a3$summary.fitted.values$mean[relevant_data],
  integerResponse = T)
plot(sim, asFactor = T)
```


```{r}
a3_spamm <- fitme(
  total_abundance ~ year + (1|siteid),
  data = test$dat_pred,
  family = "negbin")
#1/1.457
```
```{r}
simulationOutput <- simulateResiduals(fittedModel = a3_spamm)
plot(simulationOutput, asFactor = T)
testZeroInflation(simulationOutput)
testDispersion(simulationOutput)
```


```{r}
m2 <- inla(abundance ~ year:species,
  family = "poisson",
  control.family=list(link='log'),
  data = il_dataset)
summary(m2)
time_effect <- round(m2$summary.fixed, 4) %>%
  as_tibble(., rownames = "effect")
exp(time_effect$mean)
```

#

```{r}
tar_load(c(analysis_dataset))
```


```{r}
# To continue
il_dataset
model_com <- map(
  c("total_abundance_int",
    "species_nb",
    "chao_richness",
    "chao_shannon",
    "chao_simpson"),
  ~spaMM::fitme(
    as.formula(paste0(.x, "~
        year +
        unitabundance +
        (1 | ecoregion / siteid) +
        (year | first_year)")),
  data = analysis_dataset,
  family = "negbin"
)


)
usethis::use_data(model_com)
library(datasets)

mtcars
y <- "test"
library(rlang)

rm("mtcars")
load(here("data", paste0(y, ".rda")))
usethis::use_data(bquote(y))
usethis::use_data(UQ(y))
unquote(y)
!!sym(y)
UQ(enquo(y))

test

```

```{r}
analysis_dataset %>%
  ggplot(aes(x = year, y = log(total_abundance_int))) +
  geom_point() +
  geom_smooth(method = "auto")
```

```{r}
analysis_dataset %>%
  ggplot(aes(x = total_abundance_int)) +
  geom_histogram()
```

```{r}
inla_b0 <- inla(
  total_abundance_int ~
    year +
    unitabundance +
    f(siteid, model = "iid") +
    f(span, year, model = "iid"),
  family = "nbinomial",
  control.family = list(link = "log"),
  control.predictor = list(link = 1, compute = TRUE),
  control.compute = list(cpo = TRUE, dic = TRUE, config = TRUE),
  data = analysis_dataset
  )
```

```{r}
check <- distribution_check(inla_b0, nsim = 100)
plot(check)
disp <- dispersion_check(inla_b0)
plot(disp)
```

```{r}
inla_rich <- inla(
  species_nb ~
    year +
    f(siteid, model = "iid") +
    f(span, year, model = "iid"),
  family = "nbinomial",
  control.family = list(link = "log"),
  control.predictor = list(link = 1, compute = TRUE),
  control.compute = list(
    cpo = TRUE,
    dic = TRUE,
    config = TRUE,
    return.marginals.predictor = TRUE),
  data = analysis_dataset
  )
```

```{r}
get_simulated_values_negbinom <- function(inla_obj = NULL, nsim = 100) {

  post <- inla.posterior.sample(n = nsim, result = inla_obj)


  relevant <- grep("^Predictor:", rownames(post[[1]]$latent))
  eta <- map_dfc(post, "latent")[relevant, , drop = FALSE]

  relevant <- grep(
    "size for the nbinomial observations",
    names(post[[1]]$hyperpar)
  )
  size <- inla.hyperpar.sample(n = 100, result = inla_obj)[, relevant] #nolint
  simulated_values <- as_tibble(mutate_all(
      exp(eta),
      function(mu) {
        rnbinom(n = length(mu), mu = mu, size = size)
      }
      ))

  return(simulated_values)
}
get_dharma_inla_negbinom <- function(inla_obj = NULL, nsim = 100, raw_data =
  NULL, resp_var = NULL) {

  sim <- get_simulated_values_negbinom(inla_obj = inla_rich, nsim = nsim)

  relevant_data <- !is.na(raw_data[[resp_var]])
  output <- createDHARMa(
    simulatedResponse = as.matrix(sim)[relevant_data,],
    observedResponse = raw_data[[resp_var]][relevant_data],
    fittedPredictedResponse =
      inla_obj$summary.fitted.values$mean[relevant_data],
    integerResponse = T)

  return(output)

}

debugonce(get_dharma_inla_negbinom)
get_dharma_inla_negbinom(inla_obj = inla_rich, nsim = 100, raw_data =
  analysis_dataset, resp_var = "species_nb")
```

```{r}
plot(inla_rich, plot.prior = TRUE)
```


```{r}
check <- distribution_check(inla_rich, nsim = 100)
plot(check)
disp <- dispersion_check(inla_rich)
plot(disp)
```

```{r}
tar_load(c(rigal_trends, var_rigal))
names(rigal_trends) <- var_rigal
summary(rigal_trends$log_total_abundance$first_order_coefficient)
```


```{r}
b0 <- spaMM::fitme(
  total_abundance_int ~
    year +
    unitabundance +
    (1 | ecoregion / siteid) +
    (year | first_year),
  data = analysis_dataset,
  family = "negbin"
)

b0 <- spaMM::fitme(
  total_abundance_int ~
    year +
    unitabundance +
    (1 | ecoregion / siteid) +
    (year | first_year),
  data = analysis_dataset,
  family = "negbin"
)
```

```{r}
simulationOutput <- simulateResiduals(fittedModel = b0)
plot(simulationOutput, asFactor = T)
testZeroInflation(simulationOutput)
testDispersion(simulationOutput)

par(mfrow = c(1,2))
plotResiduals(simulationOutput, analysis_dataset$year)
plotResiduals(simulationOutput, analysis_dataset$unitabundance)
```

- Zero inflated:

```{r}
tb0 <- fitme(
 total_abundance_int ~ year + unitabundance + (1 | ecoregion / siteid),
  data = analysis_dataset,
  family = Tnegbin(trunc = 0L, link = "log")
)
```



## Analysis

## Reproducibility

<details><summary>Reproducibility receipt</summary>

```{r}
## datetime
Sys.time()

## repository
if(requireNamespace('git2r', quietly = TRUE)) {
  git2r::repository()
} else {
  c(
    system2("git", args = c("log", "--name-status", "-1"), stdout = TRUE),
    system2("git", args = c("remote", "-v"), stdout = TRUE)
  )
}

## session info
sessionInfo()
```

</details>
